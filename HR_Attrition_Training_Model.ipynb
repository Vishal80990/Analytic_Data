{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"snowflake-connector-python[pandas]\" \"snowflake-snowpark-python[pandas]\" snowflake-snowpark-python==1.9.0 fosforio fosforml numpy pandas matplotlib scikit-learn xgboost seaborn python-dateutil tqdm holidays faker\n",
    "!pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install fosforml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dice-ml seaborn imblearn simplejson scipy xgboost pandas dice-ml refractml tabulate numpy scikit-learn pandas-profiling plotly matplotlib scipy statsmodels seaborn dash dtale pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f1137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de740a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-4ahtbva8 because the default path (/home/mosaic-ai/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix, classification_report\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m winsorize\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats.mstats import winsorize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake.get_connection(connection_name=\"HR Attrition conn\")\n",
    "df = get_dataframe(\"Final_HR_Attrition_Data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa86868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a90e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a54582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4521113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"USER_ID\", \"JOB_START_DATE\", \"JOB_END_DATE\", \"SCHOOL_END_DATE\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1290f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78521dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"MAPPED_ROLE_CLEAN\",\"SEX\", \"ETHNICITY\",\"HOSPITAL_TYPE\", \"HOSPITAL_OWNERSHIP\",\"COMPANY_NAME\",\"CITY\",\"STATE\",\"DISTANCE\", \n",
    "                       \"DEGREE_CLEAN\",\"BUSINESS_TRAVEL\",\"ENVIRONMENT_SATISFACTION\",\"JOB_SATISFACTION\",\"MARTIAL_STATUS\",\"PERFORMANCE_RATING\",\"RELATIONSHIP_SATISFACTION\",\"WORK_LIFE_BALANCE\"]\n",
    "NUMERICAL_COLUMNS = [\"SALARY\", \"SENIORITY\", \"TENURE_MONTHS\", \"MONTHS_AFTER_COLLEGE\", \"BIRTH_YEAR\",\"AGE\", \"OVER_TIME_HOURS\", \"PERCENTAGE_SALARY_HIKE\",]\n",
    "LABEL_COLUMNS = [\"CHURN\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fd143",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = CATEGORICAL_COLUMNS + NUMERICAL_COLUMNS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in feature_columns if col in df.columns]\n",
    "LABEL_COLUMNS = [col for col in LABEL_COLUMNS if col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_columns]\n",
    "Y = df[LABEL_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f66216",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_df and test_df are both snowpark dataframes\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    ")\n",
    "\n",
    "numerical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    MinMaxScaler(clip=True)\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, CATEGORICAL_COLUMNS),\n",
    "        ('num', numerical_transformer, NUMERICAL_COLUMNS)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "result = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "filename = \"HR_Attrition_ml_model.joblib\"\n",
    "dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb782f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = X_test\n",
    "train = X_train\n",
    "train[\"CHURN\"] = train[\"CHURN\"].apply(lambda x: 1 if x else 0)\n",
    "pred = model.predict(test)\n",
    "pred[\"probabilities\"] = model.predict_proba(test)[[\"predict_proba_True\"]]\n",
    "test[\"PREDICTION\"] = pred[\"PREDICTION\"]\n",
    "test[\"probabilities\"] = pred[\"probabilities\"]\n",
    "test[\"CHURN\"] = test[\"CHURN\"].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "y_prob = np.array(test[\"probabilities\"])\n",
    "y_test = pred[\"CHURN\"]\n",
    "y_pred = pred[\"PREDICTION\"]\n",
    "X_train = train.drop([\"CHURN\"], axis=1)\n",
    "X_test = pred.drop([\"CHURN\", \"PREDICTION\", \"probabilities\"], axis=1)\n",
    "y_train = train[\"CHURN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict (X_test)\n",
    "y_prob = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d346ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(payload_dict,index=[0])\n",
    "    prediction = str(model.predict(data)[0])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365cec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in refract.\n",
    "tmp = register_model(pipeline, \n",
    "               score, \n",
    "               name=\"HR_Analytic_ml_model\", \n",
    "               description=\"HR_ANALYTICS_model_trained_using _ml\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               init_script=\"\\\\n pip install fosforml \\\\n pip install fosforio[snowflake] \\\\n pip install seaborn \\\\n pip install snowflake-connector-python[pandas] \\\\n pip install joblib==1.3.2 scikit-learn=1.3.2\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred, \n",
    "               features=X_train.columns,\n",
    "               labels=[0,1],\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               prob=y_prob,\n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train,\n",
    "               y_test=y_test,\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               target_names=['NOT LEFT','LEFT'],\n",
    "               kyd=True, kyd_score = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = {\"payload\": X_test.iloc[0].to_dict()}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e6f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
