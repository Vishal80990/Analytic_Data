{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install fosforml numpy pandas matplotlib scikit-learn seaborn python-dateutil\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install fosforml \n",
    "!pip install fosforio\n",
    "!pip install refractio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn scipy xgboost pandas dice-ml tabulate numpy scikit-learn pandas-profiling plotly matplotlib scipy statsmodels seaborn pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de740a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251cc1ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'snowflake' from 'fosforml' (/tmp/pip_packages/fosforml/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m snowflake\n\u001b[1;32m      2\u001b[0m snowflake\u001b[38;5;241m.\u001b[39mget_connection(connection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal hr attrition data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'snowflake' from 'fosforml' (/tmp/pip_packages/fosforml/__init__.py)"
     ]
    }
   ],
   "source": [
    "from fosforml import snowflake\n",
    "snowflake.get_connection(connection_name=\"Final hr attrition data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f080375a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snowflake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msnowflake\u001b[49m\u001b[38;5;241m.\u001b[39mget_connection(connection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal hr attrition data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m get_dataframe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal_HR_Attrition_Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snowflake' is not defined"
     ]
    }
   ],
   "source": [
    "snowflake.get_connection(connection_name=\"Final hr attrition data\")\n",
    "df = get_dataframe(\"Final_HR_Attrition_Data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d7bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/HR_Analytical_Data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa86868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a90e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a54582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4521113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"USER ID\", \"JOB START DATE\", \"JOB END DATE\", \"SCHOOL END DATE\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1290f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78521dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"MAPPED ROLE CLEAN\",\"SEX\", \"ETHNICITY\",\"HOSPITAL TYPE\", \"HOSPITAL OWNERSHIP\",\"COMPANY NAME\",\"CITY\",\"STATE\",\"DISTANCE\", \n",
    "                       \"DEGREE CLEAN\",\"BUSINESS TRAVEL\",\"ENVIRONMENT SATISFACTION\",\"JOB SATISFACTION\",\"MARTIAL STATUS\",\"PERFORMANCE RATING\",\"RELATIONSHIP SATISFACTION\",\"WORK LIFE BALANCE\"]\n",
    "NUMERICAL_COLUMNS = [\"SALARY\", \"SENIORITY\", \"TENURE MONTHS\", \"MONTHS AFTER COLLEGE\", \"BIRTH YEAR\",\"AGE\", \"OVER TIME HOURS\", \"PERCENTAGE SALARY HIKE\",]\n",
    "LABEL_COLUMNS = [\"CHURN\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fd143",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = CATEGORICAL_COLUMNS + NUMERICAL_COLUMNS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in feature_columns if col in df.columns]\n",
    "LABEL_COLUMNS = [col for col in LABEL_COLUMNS if col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_columns]\n",
    "Y = df[LABEL_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f66216",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_df and test_df are both snowpark dataframes\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    ")\n",
    "\n",
    "numerical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    MinMaxScaler(clip=True)\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, CATEGORICAL_COLUMNS),\n",
    "        ('num', numerical_transformer, NUMERICAL_COLUMNS)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "result = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "filename = \"HR_Attrition_ml_model.joblib\"\n",
    "dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcbca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb782f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = X_test\n",
    "train = y_train\n",
    "train[\"CHURN\"] = train[\"CHURN\"].apply(lambda x: 1 if x else 0)\n",
    "pred = model.predict(test)\n",
    "pred[\"probabilities\"] = model.predict_proba(test)[[\"predict_proba_True\"]]\n",
    "test[\"PREDICTION\"] = pred[\"PREDICTION\"]\n",
    "test[\"probabilities\"] = pred[\"probabilities\"]\n",
    "test[\"CHURN\"] = test[\"CHURN\"].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "y_prob = np.array(test[\"probabilities\"])\n",
    "y_test = pred[\"CHURN\"]\n",
    "y_pred = pred[\"PREDICTION\"]\n",
    "X_train = train.drop([\"CHURN\"], axis=1)\n",
    "X_test = pred.drop([\"CHURN\", \"PREDICTION\", \"probabilities\"], axis=1)\n",
    "y_train = train[\"CHURN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_prob = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d346ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(payload_dict,index=[0])\n",
    "    prediction = str(model.predict(data)[0])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365cec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in refract.\n",
    "tmp = register_model(pipeline, \n",
    "               score, \n",
    "               name=\"HR_Analytic_ml_model_Final\", \n",
    "               description=\"Final_HR_ANALYTICS_model_trained_using _ml\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               init_script=\"\\\\n pip install fosforml \\\\n pip install seaborn \\\\n pip install snowflake-connector-python[pandas] \\\\n pip install joblib==1.3.2 scikit-learn=1.3.2\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred, \n",
    "               features=X_train.columns,\n",
    "               labels=[0,1],\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               prob=y_prob,\n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train,\n",
    "               y_test=y_test,\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               target_names=['NOT LEFT','LEFT'],\n",
    "               kyd=True, kyd_score = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = {\"payload\": X_test.iloc[0].to_dict()}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e6f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
