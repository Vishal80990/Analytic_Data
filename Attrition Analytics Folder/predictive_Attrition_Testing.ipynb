{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a86fa-5bf6-400f-913c-28758ce8e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fosforml\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8dad83-ed64-4037-8503-107938e21db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "#import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba1e261-3e3b-49a9-949a-bac998a833b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "\n",
    "my_session = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edc066a-b26a-45a1-a4c3-3a96dd54d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'ATTRITION_PREDICTIVE_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78d4582-f6eb-4e59-8e0a-5daaf8d70433",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = my_session.sql(\"select * from {}\".format(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed538e93-a62a-49f5-b3f0-8a03ee310ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pandas_df = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb735877-46af-4508-9ee7-f91b45175de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPLOYEE_ID                      0\n",
      "TENURE_MONTHS                    0\n",
      "BIRTH_YEAR                       0\n",
      "AGE                              0\n",
      "SENIORITY                        0\n",
      "SCHOOL_ENDDATE                   0\n",
      "JOB_STARTDATE                    0\n",
      "JOB_ENDDATE                  90076\n",
      "CITY                             0\n",
      "DISTANCE                         0\n",
      "DEGREE_CLEAN                     0\n",
      "ETHNICITY                        0\n",
      "MARITAL_STATUS                   0\n",
      "ROLE                             0\n",
      "COMPANY_NAME                     0\n",
      "ORGANIZATION_TYPE                0\n",
      "ORGANIZATION_OWNERSHIP           0\n",
      "STATE                            0\n",
      "COUNTRY                          0\n",
      "GENDER                           0\n",
      "WORK_LIFE_BALANCE                0\n",
      "BUSINESS_TRAVEL                  0\n",
      "ENVIRONMENT_SATISFACTION         0\n",
      "SALARY                           0\n",
      "JOB_SATISFACTION                 0\n",
      "PERCENTAGE_SALARY_HIKE           0\n",
      "PERFORMANCE_RATING               0\n",
      "OVER_TIME                        0\n",
      "RELATIONSHIP_SATISFACTION        0\n",
      "CHURN                            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9343ba21-69e1-4ac0-a2fd-67a9ae514274",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_df = pandas_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3916a4-a50c-4494-acfb-c0dc94bfa5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPLOYEE_ID                  0\n",
      "TENURE_MONTHS                0\n",
      "BIRTH_YEAR                   0\n",
      "AGE                          0\n",
      "SENIORITY                    0\n",
      "SCHOOL_ENDDATE               0\n",
      "JOB_STARTDATE                0\n",
      "JOB_ENDDATE                  0\n",
      "CITY                         0\n",
      "DISTANCE                     0\n",
      "DEGREE_CLEAN                 0\n",
      "ETHNICITY                    0\n",
      "MARITAL_STATUS               0\n",
      "ROLE                         0\n",
      "COMPANY_NAME                 0\n",
      "ORGANIZATION_TYPE            0\n",
      "ORGANIZATION_OWNERSHIP       0\n",
      "STATE                        0\n",
      "COUNTRY                      0\n",
      "GENDER                       0\n",
      "WORK_LIFE_BALANCE            0\n",
      "BUSINESS_TRAVEL              0\n",
      "ENVIRONMENT_SATISFACTION     0\n",
      "SALARY                       0\n",
      "JOB_SATISFACTION             0\n",
      "PERCENTAGE_SALARY_HIKE       0\n",
      "PERFORMANCE_RATING           0\n",
      "OVER_TIME                    0\n",
      "RELATIONSHIP_SATISFACTION    0\n",
      "CHURN                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Original_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb6c69e4-5a86-46ce-89d0-af3a0dc63bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure date columns are parsed correctly\n",
    "date_columns = ['SCHOOL_ENDDATE', 'JOB_STARTDATE', 'JOB_ENDDATE']\n",
    "for col in date_columns:\n",
    "    Original_df[col] = pd.to_datetime(Original_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a33611af-4a6f-467d-bb5e-86f7ba05e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EMPLOYEE_ID  TENURE_MONTHS  BIRTH_YEAR  AGE  SENIORITY SCHOOL_ENDDATE  \\\n",
      "0    94215814             38        1981   43          1     2006-01-01   \n",
      "1    20227353             60        1991   33          1     2009-01-01   \n",
      "3    15048356              9        1992   32          1     2014-01-31   \n",
      "4    91151756             38        1981   43          1     2006-01-01   \n",
      "6    91039761              5        1987   37          1     2014-01-31   \n",
      "\n",
      "  JOB_STARTDATE JOB_ENDDATE       CITY   DISTANCE  ... WORK_LIFE_BALANCE  \\\n",
      "0    2016-06-01  2019-08-01  Charlotte   <2 miles  ...              Best   \n",
      "1    2016-06-01  2021-06-01  Charlotte   <2 miles  ...            Better   \n",
      "3    2016-10-01  2017-07-01  Charlotte   <2 miles  ...               Bad   \n",
      "4    2016-06-01  2019-08-01  Charlotte   <2 miles  ...            Better   \n",
      "6    2018-02-01  2018-07-01     Dallas  >10 miles  ...              Best   \n",
      "\n",
      "  BUSINESS_TRAVEL ENVIRONMENT_SATISFACTION    SALARY JOB_SATISFACTION  \\\n",
      "0   Travel Rarely                   Medium  43118.65             High   \n",
      "1   Travel Rarely                     High  32365.59             High   \n",
      "3   Travel Rarely                   Medium  22281.58              Low   \n",
      "4   Travel Rarely                Very High  38163.65           Medium   \n",
      "6   Travel Rarely                Very High  27599.60             High   \n",
      "\n",
      "  PERCENTAGE_SALARY_HIKE PERFORMANCE_RATING OVER_TIME  \\\n",
      "0                     20        Outstanding     False   \n",
      "1                     14        Outstanding     False   \n",
      "3                     17               Good     False   \n",
      "4                     21                Low      True   \n",
      "6                     14        Outstanding      True   \n",
      "\n",
      "  RELATIONSHIP_SATISFACTION CHURN  \n",
      "0                    Medium     1  \n",
      "1                    Medium     1  \n",
      "3                 Very High     1  \n",
      "4                    Medium     1  \n",
      "6                       Low     1  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned DataFrame\n",
    "print(Original_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ad6b3d-f53a-4418-a0c1-0507c39a16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'CHURN' is your target variable and 'TENURE_MONTHS' is a feature\n",
    "y = Original_df['CHURN']\n",
    "X = Original_df[['DEGREE_CLEAN', 'ORGANIZATION_TYPE']]  # Add more features as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b0cc6a-a9ba-499e-a4c5-cfc494514e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to the features\n",
    "import statsmodels.api as sm  # Import statsmodels\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6348f68-c7e5-4f5a-ac0b-05b4bb00aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_size = int(len(y) * 0.8)\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "X_train, X_test = X[:train_size], X[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0473a48b-19bc-4b09-86a3-3ff2200cee5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit ARIMAX model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtsa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mARIMA\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/arima/model.py:158\u001b[0m, in \u001b[0;36mARIMA.__init__\u001b[0;34m(self, endog, exog, order, seasonal_order, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[1;32m    151\u001b[0m     trend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Construct the specification\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# (don't pass specific values of enforce stationarity/invertibility,\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# because we don't actually want to restrict the estimators based on\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# this criteria. Instead, we'll just make sure that the parameter\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# estimates from those methods satisfy the criteria.)\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec_arima \u001b[38;5;241m=\u001b[39m \u001b[43mSARIMAXSpecification\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_stationarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_invertibility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcentrate_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcentrate_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_specification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_specification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec_arima\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39morig_exog\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Raise an error if we have a constant in an integrated model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/arima/specification.py:446\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[0;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[1;32m    441\u001b[0m         exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[trend_data, exog]\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Create an underlying time series model, to handle endog / exog,\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# especially validating shapes, retrieving names, and potentially\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# providing us with a time series index\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m faux_endog \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mendog\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:470\u001b[0m, in \u001b[0;36mTimeSeriesModel.__init__\u001b[0;34m(self, endog, exog, dates, freq, missing, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    469\u001b[0m ):\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# Date handling in indexes\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_dates(dates, freq)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/base/data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_endog_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/base/data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "# Fit ARIMAX model\n",
    "model = sm.tsa.ARIMA(y_train, exog=X_train, order=(1, 1, 1))\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77089c3a-e328-47f8-bad0-12bca16865b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model_fit.forecast(steps=len(y_test), exog=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221ced2-7bee-4d87-8196-40ff1ce38634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4643c-216d-40e1-9b5a-6fc0853cd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the next 12 months\n",
    "future_steps = 12\n",
    "future_exog = X_test.iloc[-1:].append([X_test.iloc[-1:]] * (future_steps - 1), ignore_index=True)  # Adjust exogenous variables as needed\n",
    "predictions = model_fit.forecast(steps=future_steps, exog=future_exog)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842b523-c468-4af3-ab13-99a00a79935c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e0c57-33a0-4f8d-b99b-f87409b35ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acfa1f-7eb6-47e2-b293-69c98765b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Original_df[[\"DISTANCE\",\"DEGREE_CLEAN\",\"ROLE\",\"COMPANY_NAME\",\"ORGANIZATION_TYPE\",\"ORGANIZATION_OWNERSHIP\",\"JOB_ENDDATE\",\"CHURN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2183265-3b36-4628-94cf-9bcb3293e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b268ca-3f7e-4109-a810-e5871326dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['JOB_ENDDATE'] = pd.to_datetime(df['JOB_ENDDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffa0bc-c71a-40d0-9489-7ebea94bafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('JOB_ENDDATE', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb7d40-0673-4c80-a1a6-bad060538ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the index is unique\n",
    "df = df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0137a0e-0700-4a85-982d-33d1cd0c028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by categorical columns and resample monthly, then sum CHURN\n",
    "New_df = df.groupby([\"DISTANCE\", \"DEGREE_CLEAN\", \"ROLE\", \"COMPANY_NAME\", \"ORGANIZATION_TYPE\", \"ORGANIZATION_OWNERSHIP\"]).resample('M').agg({'CHURN': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25ba73-ac47-42bd-af88-7483e64650b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where CHURN is greater than 0\n",
    "df1 = New_df[New_df['CHURN'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b4deb-f023-451c-86fc-784fb0a9507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c3e7a-8b3e-44bc-970d-572bcff7b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date column as index\n",
    "df1.set_index('JOB_ENDDATE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601964e9-2801-4924-8ddc-2e9acb865b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the index is unique\n",
    "df1 = df1[~df1.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512624c-1271-474f-8a33-5950d15700d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train = df1[:pd.Timestamp('2024-08-31')]\n",
    "test = df1[pd.Timestamp('2024-09-01'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c3539-1bd6-47a5-bf6e-e28ac006faab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64c8bf-6d3d-4af8-b095-ce8aea6bc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure date column is in datetime format\n",
    "df1['JOB_ENDDATE'] = pd.to_datetime(df1['JOB_ENDDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ec9ea-850f-4710-ba03-2d64bd31fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the index is unique\n",
    "df = df[~df.index.duplicated(keep='first')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa7727-6604-44dc-a2a6-d650a7c6ce36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42c545-f3a1-4225-b7dc-c4bc3ea057b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a195e-4f17-413c-b95a-6f984f26f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date column as index\n",
    "df1.set_index('JOB_ENDDATE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4a664-2f48-4b00-98db-f1509eff9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train = df1[:pd.Timestamp('2024-08-31')]\n",
    "test = df1[pd.Timestamp('2024-09-01'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8666435-1f50-444a-b53d-853904caf8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79dcf1c-955f-4be7-92fe-d01eec935a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c6d37-a1e4-4a10-8310-0d5af29e6486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a7203-94fc-48fb-98ca-52829f14e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train = df1[:'2024-08']\n",
    "test = df1['2024-09':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac344f-dea6-4ced-8cf7-8e974d79bf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e087c2d-7a4b-4f1b-b518-53abe875cf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f510b-f872-4de7-a842-dbdb120bf59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['JOB_ENDDATE'] = pd.to_datetime(df['JOB_ENDDATE'])\n",
    "monthly_data = df.resample('M', on='JOB_ENDDATE').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe265e37-dcef-4fa2-a631-dc2effc782ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee3fd1-4eb6-4025-a591-f3e47e03f50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
