{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bbdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install fosforml numpy pandas matplotlib scikit-learn seaborn python-dateutil\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install fosforml \n",
    "!pip install fosforio\n",
    "!pip install refractio\n",
    "!pip install refractml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn scipy xgboost pandas Faker dice-ml tabulate numpy scikit-learn pandas-profiling plotly matplotlib scipy statsmodels seaborn pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d30aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Generate 300,000 records\n",
    "num_records = 300000\n",
    "\n",
    "# Prepare a list to store all the generated records\n",
    "records = []\n",
    "\n",
    "# Generate realistic data for each record\n",
    "for _ in range(num_records):\n",
    "    city = fake.city()\n",
    "    state = fake.state_abbr()\n",
    "    first_name = fake.first_name()\n",
    "    last_name = fake.last_name()\n",
    "    gender = random.choice([\"Male\", \"Female\"])\n",
    "    dob = fake.date_of_birth(minimum_age=18, maximum_age=90).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Create a dictionary for the current record\n",
    "    record = {\n",
    "        \"City\": city,\n",
    "        \"State\": state,\n",
    "        \"First Name\": first_name,\n",
    "        \"Last Name\": last_name,\n",
    "        \"Gender\": gender,\n",
    "        \"DOB\": dob\n",
    "    }\n",
    "\n",
    "    # Add the dictionary to the records list\n",
    "    records.append(record)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"realistic_data.csv\", index=False)\n",
    "\n",
    "print(f\"Generated {num_records} realistic records and saved to realistic_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4317e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    " \n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "Faker.seed(0)\n",
    "random.seed(0)\n",
    " \n",
    "# Predefined list of 50 unique US cities\n",
    "unique_cities = [\n",
    "    'Los Angeles', 'San Francisco', 'San Diego', 'San Jose', 'Fresno',\n",
    "    'New York City', 'Buffalo', 'Rochester', 'Syracuse', 'Albany',\n",
    "    'Houston', 'Dallas', 'Austin', 'San Antonio', 'El Paso',\n",
    "    'Miami', 'Orlando', 'Tampa', 'Jacksonville', 'St. Petersburg',\n",
    "    'Chicago', 'Aurora', 'Naperville', 'Joliet', 'Rockford',\n",
    "    'Philadelphia', 'Pittsburgh', 'Allentown', 'Erie', 'Reading',\n",
    "    'Columbus', 'Cleveland', 'Cincinnati', 'Toledo', 'Akron',\n",
    "    'Atlanta', 'Augusta', 'Columbus', 'Macon', 'Savannah',\n",
    "    'Charlotte', 'Raleigh', 'Greensboro', 'Durham', 'Winston-Salem',\n",
    "    'Detroit', 'Grand Rapids', 'Warren', 'Sterling Heights', 'Lansing'\n",
    "]\n",
    " \n",
    "# Map of states corresponding to the unique cities\n",
    "# Adjust as needed based on the cities list\n",
    "state_city_mapping = {\n",
    "    'California': ['Los Angeles', 'San Francisco', 'San Diego', 'San Jose', 'Fresno'],\n",
    "    'New York': ['New York City', 'Buffalo', 'Rochester', 'Syracuse', 'Albany'],\n",
    "    'Texas': ['Houston', 'Dallas', 'Austin', 'San Antonio', 'El Paso'],\n",
    "    'Florida': ['Miami', 'Orlando', 'Tampa', 'Jacksonville', 'St. Petersburg'],\n",
    "    'Illinois': ['Chicago', 'Aurora', 'Naperville', 'Joliet', 'Rockford'],\n",
    "    'Pennsylvania': ['Philadelphia', 'Pittsburgh', 'Allentown', 'Erie', 'Reading'],\n",
    "    'Ohio': ['Columbus', 'Cleveland', 'Cincinnati', 'Toledo', 'Akron'],\n",
    "    'Georgia': ['Atlanta', 'Augusta', 'Columbus', 'Macon', 'Savannah'],\n",
    "    'North Carolina': ['Charlotte', 'Raleigh', 'Greensboro', 'Durham', 'Winston-Salem'],\n",
    "    'Michigan': ['Detroit', 'Grand Rapids', 'Warren', 'Sterling Heights', 'Lansing']\n",
    "}\n",
    " \n",
    "# Generate a list of states from the mapping\n",
    "states = list(state_city_mapping.keys())\n",
    " \n",
    "# Create a function to generate data\n",
    "def generate_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        state = random.choice(states)\n",
    "        city = random.choice(state_city_mapping[state])\n",
    "        name = fake.name()\n",
    "        gender = random.choice(['Male', 'Female'])\n",
    "        dob = fake.date_of_birth(minimum_age=18, maximum_age=80).strftime('%Y-%m-%d')\n",
    "        data.append([city, state, name, gender, dob])\n",
    "    return data\n",
    " \n",
    "# Generate 300,000 records\n",
    "num_records = 300000\n",
    "records = generate_data(num_records)\n",
    " \n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(records, columns=['City', 'State', 'Name', 'Gender', 'DOB'])\n",
    " \n",
    "# Save to a CSV file\n",
    "df.to_csv('synthetic_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faker us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf932a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
