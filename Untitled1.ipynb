{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bbdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install fosforml numpy pandas matplotlib scikit-learn seaborn python-dateutil\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install fosforml \n",
    "!pip install fosforio\n",
    "!pip install refractio\n",
    "!pip install refractml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn scipy xgboost pandas Faker dice-ml tabulate numpy scikit-learn pandas-profiling plotly matplotlib scipy statsmodels seaborn pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dae6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e1cb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300000 realistic records and saved to realistic_data.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Generate 300,000 records\n",
    "num_records = 300000\n",
    "\n",
    "# Prepare a list to store all the generated records\n",
    "records = []\n",
    "\n",
    "# Generate realistic data for each record\n",
    "for _ in range(num_records):\n",
    "    city = fake.city()\n",
    "    state = fake.state_abbr()\n",
    "    first_name = fake.first_name()\n",
    "    last_name = fake.last_name()\n",
    "    gender = random.choice([\"Male\", \"Female\"])\n",
    "    dob = fake.date_of_birth(minimum_age=18, maximum_age=90).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Create a dictionary for the current record\n",
    "    record = {\n",
    "        \"City\": city,\n",
    "        \"State\": state,\n",
    "        \"First Name\": first_name,\n",
    "        \"Last Name\": last_name,\n",
    "        \"Gender\": gender,\n",
    "        \"DOB\": dob\n",
    "    }\n",
    "\n",
    "    # Add the dictionary to the records list\n",
    "    records.append(record)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"realistic_data.csv\", index=False)\n",
    "\n",
    "print(f\"Generated {num_records} realistic records and saved to realistic_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a307f56",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'us'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfaker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Faker\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mus\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize Faker\u001b[39;00m\n\u001b[1;32m      7\u001b[0m fake \u001b[38;5;241m=\u001b[39m Faker()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'us'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import us\n",
    " \n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "Faker.seed(0)\n",
    "random.seed(0)\n",
    " \n",
    "# Get US states and cities from us package\n",
    "states = us.states.STATES_ABBR  # List of state abbreviations\n",
    "state_city_mapping = {}\n",
    " \n",
    "# Create a mapping of states to cities\n",
    "for state in states:\n",
    "    # Generate a list of cities for each state\n",
    "    # Faker does not support actual city names, so we use fake city names\n",
    "    # For more accurate cities, consider using a static list or an API\n",
    "    state_city_mapping[state] = [fake.city() for _ in range(10)]\n",
    " \n",
    "# Create a function to generate data\n",
    "def generate_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        state = random.choice(states)\n",
    "        city = random.choice(state_city_mapping[state])\n",
    "        name = fake.name()\n",
    "        gender = random.choice(['Male', 'Female'])\n",
    "        dob = fake.date_of_birth(minimum_age=18, maximum_age=80).strftime('%Y-%m-%d')\n",
    "        data.append([city, state, name, gender, dob])\n",
    "    return data\n",
    " \n",
    "# Generate 300,000 records\n",
    "num_records = 300000\n",
    "records = generate_data(num_records)\n",
    " \n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(records, columns=['City', 'State', 'Name', 'Gender', 'DOB'])\n",
    " \n",
    "# Save to a CSV file\n",
    "df.to_csv('synthetic_data_us.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3185630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faker us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b32e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
