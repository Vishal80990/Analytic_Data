{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1eedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install fosforml numpy pandas matplotlib scikit-learn seaborn python-dateutil\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install fosforml \n",
    "!pip install fosforio\n",
    "!pip install refractio\n",
    "!pip install refractml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c194bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn scipy xgboost pandas dice-ml tabulate numpy scikit-learn pandas-profiling plotly matplotlib scipy statsmodels seaborn pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from refractio import snowflake\n",
    "snowflake.get_connection(connection_name=\"HR_Attrition_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5dff18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snowflake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Original_df \u001b[38;5;241m=\u001b[39m \u001b[43msnowflake\u001b[49m\u001b[38;5;241m.\u001b[39mget_dataframe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHR_Attrition_Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snowflake' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022eee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b64822",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop([\"USER_ID\", \"EMPLOYEE_ID\", \"JOB_STARTDATE\", \"JOB_ENDDATE\", \"SCHOOL_ENDDATE\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"MAPPED_ROLE_CLEAN\",\"SEX\", \"ETHNICITY\",\"HOSPITAL_TYPE\", \"HOSPITAL_OWNERSHIP\",\"COMPANY_NAME\",\"CITY\",\"STATE\",\"DISTANCE\", \n",
    "                       \"DEGREE_CLEAN\",\"BUSINESS_TRAVEL\",\"ENVIRONMENT_SATISFACTION\",\"JOB_SATISFACTION\",\"MARITAL_STATUS\",\"OVER_TIME\",\"PERFORMANCE_RATING\",\"RELATIONSHIP_SATISFACTION\",\"WORK_LIFE_BALANCE\"]\n",
    "NUMERICAL_COLUMNS = [\"USER_ID\",\"EMPLOYEE_ID\",\"SALARY\", \"SENIORITY\", \"TENURE_MONTHS\", \"MONTHS_AFTER_COLLEGE\", \"BIRTH_YEAR\",\"AGE\",\"OVERTIME_HOURS\",\"PERCENTAGE_SALARY_HIKE\"]\n",
    "DATE_COLUMNS = [\"JOB_STARTDATE\",\"JOB_ENDDATE\",\"SCHOOL_ENDDATE\"]\n",
    "LABEL_COLUMNS = [\"CHURN\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter feature columns\n",
    "feature_columns = CATEGORICAL_COLUMNS + NUMERICAL_COLUMNS + DATE_COLUMNS\n",
    "feature_columns = [col for col in feature_columns if col in df.columns]\n",
    "LABEL_COLUMNS = [col for col in LABEL_COLUMNS if col in df.columns]\n",
    " \n",
    "# Split data into features and labels\n",
    "X = df[feature_columns]\n",
    "y = df[LABEL_COLUMNS].values.ravel()  # Flatten to 1D array for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fb664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5daaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    " \n",
    "# Define transformers\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    ")\n",
    " \n",
    "numerical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    MinMaxScaler(clip=True)\n",
    ")\n",
    " \n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, CATEGORICAL_COLUMNS),\n",
    "        ('num', numerical_transformer, NUMERICAL_COLUMNS)\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "result = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "filename = \"HR_Attrition.joblib\"\n",
    "dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01beffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_prob = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from refractml import *\n",
    "\n",
    "from refractml.constants import MLModelFlavours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15057042",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data_json = eval(payload)\n",
    "    data = pd.DataFrame([data_json])\n",
    "    prediction = str(model.predict(data)[0])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76805fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "payload = str(X_test.iloc[123].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "\n",
    "print(score(pipeline, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "req.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317150b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in refract.\n",
    "tmp = register_model(pipeline, \n",
    "               score, \n",
    "               name=\"HR_ATTRITION_ML_MODEL\", \n",
    "               description=\"Analyzing_HR_Attrition_trained_using _ml\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               init_script=\"\\\\n pip install fosforml \\\\n pip install seaborn \\\\n pip install snowflake-connector-python[pandas] \\\\n pip install joblib==1.3.2 scikit-learn=1.3.2\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred, \n",
    "               features=X_train.columns,\n",
    "               labels=[0,1],\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               prob=y_prob,\n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train,\n",
    "               y_test=y_test,\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               target_names=['NOT LEFT','LEFT'],\n",
    "               kyd=True, kyd_score = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = {\"payload\": X_test.iloc[0].to_dict()}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9cff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={\"Content-type\":\"application/json\"}\n",
    "url = \"http://svc-32a60b58-45e6-42da-874a-1c703d935a77:5001/hrattritionmlmodel/e782fefe-2c69-4a1a-bdf2-4489e3f06da0/score\"\n",
    "data={\"payload\": payload}\n",
    "response = requests.post(url, json=data, headers=headers) \n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.predict(X_test)\n",
    "result_prob = pipeline.predict_proba(X_test)\n",
    "pred_df = X_test.copy()\n",
    "result = result\n",
    "result_prob = result_prob\n",
    "pred_df[\"PREDICTION\"] = result\n",
    "pred_df[\"PROB\"] = result_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, log_loss, roc_auc_score\n",
    " \n",
    "# Check lengths\n",
    "print(\"Length of y_test:\", len(y_test))\n",
    "print(\"Length of y_pred:\", len(y_pred))\n",
    " \n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = sum(y_test == y_pred) / len(y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    " \n",
    "# Calculate additional metrics\n",
    "log_loss_value = log_loss(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob[:, 1])  # Assuming class 1 is the positive class\n",
    " \n",
    "print(\"Log Loss:\", log_loss_value)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae90976",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test,pred_df[\"PROB\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a16c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, pred_df[\"PROB\"])\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, pred_df[\"PROB\"])\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Radnomforest')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e34f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, pred_df[\"PROB\"])\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='Randomforest')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc04f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    " \n",
    "#Plot the confusion matrix.\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            xticklabels=['Not Churn','Churn'],\n",
    "            yticklabels=['Not CHurn','Churn'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8407141",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data = pd.DataFrame({\"ns_probs\":ns_probs,\n",
    "                            \"y_test\":y_test,\n",
    "                            \"y_pred\":pred_df[\"PREDICTION\"],\n",
    "                            \"act_probs\":pred_df[\"PROB\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data.to_csv(\"/data/scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of ns_probs: {len(ns_probs)}\")\n",
    "print(f\"Length of y_pred: {len(pred_df['PREDICTION'])}\")\n",
    "print(f\"Length of y_test_binary: {len(y_test)}\")\n",
    "print(f\"Length of act_probs: {len(pred_df['PROB'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define or use the prediction function\n",
    "def model_prediction_score_func(dataframe):\n",
    "    # Ensure 'dataframe' has the correct features required by the model\n",
    "    return pipeline.predict(dataframe)  # Use your trained pipeline/model here\n",
    " \n",
    "# Assuming df is your input DataFrame with the necessary features\n",
    "df['Model_Output'] = model_prediction_score_func(df)\n",
    " \n",
    "# If you have a DataFrame with test data and you want to merge predictions\n",
    "# Assuming X_test is the DataFrame for which predictions are made\n",
    "X_test_with_predictions = X_test.copy()\n",
    "X_test_with_predictions['Model_Output'] = model_prediction_score_func(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of ns_probs: {len(ns_probs)}\")\n",
    "print(f\"Length of y_pred: {len(pred_df['PREDICTION'])}\")\n",
    "print(f\"Length of y_test_binary: {len(y_test_binary)}\")\n",
    "print(f\"Length of act_probs: {len(pred_df['PROB'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556fccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows to verify\n",
    "print(X_test_with_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef205214",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_with_predictions.to_csv(\"/data/combined_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake.execute_query(f\"PUT file://data/combined_predictions.csv @HR_ANALYTIC.HR_ATTRITION.HR_ANALYTICAL_DATA_ATTRITION_STAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba653f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = snowflake.get_connection(\"HR_Attrition_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'HR_Attrition_Model_Data.csv'\n",
    "X_test_with_predictions.to_csv(file , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake.execute_query(f\"PUT file://{file} @HR_ANALYTIC.HR_ATTRITION.HR_ANALYTICAL_DATA_ATTRITION_STAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake.execute_query(f\"PUT file:// @HR_ANALYTIC.HR_ATTRITION.HR_ANALYTICAL_DATA_ATTRITION_STAGE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
